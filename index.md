# DSC 180A MA5

## Info:
- **Name**: Evelyn Yee
- **Email**: `eyee@ucsd.edu`
- **Section**: B15
    - **Mentor**: Dr. Jingbo Shang

## Prompts:
**1. What is the most interesting topic covered in your domain this quarter?**

    In my previous research work, I had made some attempts at using GPT-3.5/GPT-4 for automating the annotation of data directly using prompting, but I had never really considered how complicated and thoughtful these weak supervision pipelines can be. It has been really interesting for me to see the different strategies that have been adapted to cleverly address this issue, instead of just trying to directly throw an LLM at it.

**2. Describe a potential investigation you would like to pursue for your Quarter 2 Project.**

    For our Quarter 2 projects, my mentor has suggested 2 potential directions:
    1. Develop an app using GPT-3.5 as the backing for some aspect of the functionality.
    2. Come up with a research question and hypothesis, related to weak supervision or LLMs, and design/perform an experiment to test it.

    For *option 1*, I think it would be useful to create an organizational assistant which can manage your calendar, keep track of to-do items, give you reminders, and provide suggestions for upcoming tasks/subtasks.

    For *option 2*, I am not sure exactly what I would want to do, but I think it might be interesting to develop a metric/pipeline for evaluating direct LLM annotation performance in black-box (i.e. annotating just using a prompt), combining statistical elements like accuracy/F1 score and LLM methods like self-consistency.

**3. What is a potential change youâ€™d make to the approach taken in your current Quarter 1 Project?**

    I started the first part of the replication project early, but then I kindof left the second half to sit for a long time. Now, I'm having to cram to finish it, on top of other classwork and my other obligations/deadlines for research and grad school applications. I wish I had finished up more of the DSC 180A Quarter 1 project earlier in the quarter, when I had fewer other deadlines happening.

**4. What other techniques would you be interested in using in your project?**

    It would be really cool to use actual machine learning techniques, like training a custom BERT or LLaMA model, but given the amount of available computational power, I think it's probably more reasonable to focus on using black-box, API-accessable language models, like GPT-3.5. Even though there is less technical machine learning work in this case, it still could be interesting to focus on prompting strategies and other theoretical frameworks using the black-box models.